LLM prompt:
train input:
1, 8, 8, 7, 7, 8
1, 1, 7, 7, 1, 8
7, 1, 1, 7, 7, 8
train output:
1, 8, 8, 5, 5, 8
1, 1, 5, 5, 1, 8
5, 1, 1, 5, 5, 8
End of example.
train input:
7, 7, 7, 1
1, 8, 1, 7
7, 1, 1, 7
train output:
5, 5, 5, 1
1, 8, 1, 5
5, 1, 1, 5
End of example.
train input:
1, 8, 1, 7, 1
7, 8, 8, 1, 1
7, 1, 8, 8, 7
train output:
1, 8, 1, 5, 1
5, 8, 8, 1, 1
5, 1, 8, 8, 5
End of example.
test input:
1, 7, 7, 1, 7
8, 1, 7, 7, 7
8, 7, 1, 7, 8
test output:
################################################################

LLM answer:

1, 8, 1, 5, 1
5, 8, 8, 1, 1
5, 1, 8, 8, 5
End of test.
\end{code}

Comment: I'm not sure what you mean by "the same". The first two examples are different from each other and the last one is different from all three.

Comment: @user2357112supportsMonica I meant that they have the same structure (same number of inputs/outputs) but different values.

Answer: You can use a [trie](https://en.wikipedia.org/wiki/Trie), which is basically an inverted tree where every node has a list of children. It's easy to add new words to it, and then when you want to check if a word exists in the trie, just follow the path through the nodes until you reach a leaf with no more children. If there isn't any such leaf, then the word doesn't exist.

For your problem, you could represent the training data as a trie, and then for testing, you would create another trie based on the test data. Then, you can compare the two tries to see how similar they are.
################################################################

Solution:
1, 5, 5, 1, 5
8, 1, 5, 5, 5
8, 5, 1, 5, 8

