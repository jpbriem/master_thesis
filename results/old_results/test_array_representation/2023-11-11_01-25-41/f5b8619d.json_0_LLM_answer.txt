Input token: 822
Output token: 1003
################################################################

LLM prompt:
train input:
[[2, 0, 0], [0, 0, 0], [0, 0, 2]]
train output:
[[2, 0, 8, 2, 0, 8], [8, 0, 8, 8, 0, 8], [8, 0, 2, 8, 0, 2], [2, 0, 8, 2, 0, 8], [8, 0, 8, 8, 0, 8], [8, 0, 2, 8, 0, 2]]

train input:
[[0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 5], [0, 0, 0, 0, 0, 0]]
train output:
[[8, 5, 0, 0, 0, 8, 8, 5, 0, 0, 0, 8], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [5, 8, 0, 0, 0, 5, 5, 8, 0, 0, 0, 5], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [8, 5, 0, 0, 0, 8, 8, 5, 0, 0, 0, 8], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8], [5, 8, 0, 0, 0, 5, 5, 8, 0, 0, 0, 5], [8, 8, 0, 0, 0, 8, 8, 8, 0, 0, 0, 8]]

train input:
[[0, 4], [0, 0]]
train output:
[[0, 4, 0, 4], [0, 8, 0, 8], [0, 4, 0, 4], [0, 8, 0, 8]]

test input:
[[0, 0, 3, 0], [0, 0, 0, 0], [0, 0, 0, 3], [3, 0, 0, 0]]
################################################################

LLM answer:

test output:
[[0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16], [0, 0, 16, 0, 0, 16, 0, 0, 16, 0, 0, 16]]
'''
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score

def knn(X_train, y_train, X_test):
    # 1. 训练数据集划分为k个子集，每个子集中的样本数量相同
    k = len(y_train) // 2
    # 2. 将第一个子集作为测试集，其余k-1个子集作为训练集
    for i in range(len(y_train)):
        if i % k == 0 and i!= 0:
            test_index = list(range((i - k), (i)))
            train_index = list(set(list(range(len(y_train)))) - set(test_index))
            print('第{}次交叉验证'.format(i + 1))
            print('测试集：', X_train[test_index])
            print('训练集：', X_train[train_index])
            print()
            clf = KNeighborsClassifier(n_neighbors=7)
            clf.fit(X_train[train_index], y_train[train_index])
            y_pred = clf.predict(X_train[test_index])
            score = accuracy_score(y_train[test_index], y_pred)
            print('准确率：{:.2%}'.format(score))
            print()

if __name__ == '__main__':
    # 读取数据
    data = np.loadtxt('./data/mnist_all.csv', delimiter=',')
    # 划分训练集和测试集
    X_train = data[:-1000]
    y_train = data[-1000:, 0]
    X_test = data[-1000:][:-1]
    # 调用函数进行KNN模型的交叉验证
    knn(X_train, y_train, X_test)
################################################################

Solution:
[[8, 0, 3, 8, 8, 0, 3, 8], [8, 0, 8, 8, 8, 0, 8, 8], [8, 0, 8, 3, 8, 0, 8, 3], [3, 0, 8, 8, 3, 0, 8, 8], [8, 0, 3, 8, 8, 0, 3, 8], [8, 0, 8, 8, 8, 0, 8, 8], [8, 0, 8, 3, 8, 0, 8, 3], [3, 0, 8, 8, 3, 0, 8, 8]]

