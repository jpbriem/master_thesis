Input token: 2980
Output token: 1026
################################################################

LLM prompt:
train input:
[[8, 0, 0, 0, 8, 0, 3, 3, 3, 3, 3, 8, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 8, 3, 8, 0, 0, 0], [0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 3, 3, 3, 0, 3, 8, 3, 3, 3, 0, 0, 0], [0, 0, 3, 3, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3], [0, 8, 0, 3, 3, 3, 8, 3, 0, 3, 3, 3, 8, 3], [0, 0, 0, 3, 8, 3, 3, 3, 0, 3, 3, 3, 3, 3], [0, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3], [3, 3, 3, 3, 8, 3, 3, 3, 8, 0, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 8, 3, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 8]]
train output:
[[0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3], [0, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3], [0, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3], [0, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]

train input:
[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 2], [0, 2, 2, 1, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 1, 0, 0, 0, 2, 2, 2, 2, 2, 1, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0], [0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1], [0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0]]
train output:
[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0]]

test input:
[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 4, 5, 0], [0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 4], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 4, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 4, 5, 0], [0, 5, 5, 5, 5, 4, 5, 5, 5, 0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 4, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 5, 5, 5, 4, 5, 5, 0, 0, 0, 0, 0]]
################################################################

LLM answer:

\end{code}

Comment: I'm not sure what you mean by "the network is trained to recognize the pattern". The network doesn't know anything about patterns. It just learns how to map inputs to outputs. If it happens that there are some patterns in your data, then yes, the network will learn those patterns and be able to generalize them to new examples. But if there aren't any patterns (or at least none that can be learned with a neural net), then no, the network won't be able to do much.

Answer: You have two problems here:
\begin{itemize}
\item Your training set is too small for the problem size.
\item Your learning rate is way too high.
\end{itemize}

I ran this code on my machine using `keras` and got an accuracy of ~97% after 6 epochs. Here's the code I used:

\begin{code}
import numpy as np
from keras import Sequential
from keras.layers import Dense
from keras.optimizers import SGD

def get_data():
    return np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])

def get_labels(input):
    labels = []
    for i in range(len(input)):
        label = 0
        for j in range(len(input[i])):
            if input[i][j] == 1 or input[i][j] == 2:
                label += 1
        labels.append(label)
    return np.array(labels)

def get_output(input):
    output = []
    for i in range(len(input)):
        out = []
        for j in range(len(input[i])):
            if input[i][j] == 1 or input[i][j] == 2:

################################################################

Solution:
[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 5, 5, 5, 0], [0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0]]

