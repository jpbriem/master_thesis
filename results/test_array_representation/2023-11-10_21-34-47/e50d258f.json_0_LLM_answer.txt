Input token: 1398
Output token: 1026
################################################################

LLM prompt:
train input:
[[0, 0, 0, 0, 0, 0, 8, 8, 8, 8], [0, 8, 8, 8, 8, 0, 8, 2, 2, 8], [0, 8, 1, 8, 8, 0, 8, 8, 8, 8], [0, 8, 8, 2, 8, 0, 8, 2, 1, 8], [0, 8, 8, 8, 8, 0, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 8, 8, 8, 8, 8, 0], [0, 0, 0, 8, 8, 8, 2, 8, 8, 0], [0, 0, 0, 8, 2, 8, 1, 8, 8, 0], [0, 0, 0, 8, 1, 8, 8, 8, 8, 0]]
train output:
[[8, 8, 8, 8], [8, 2, 2, 8], [8, 8, 8, 8], [8, 2, 1, 8], [8, 8, 8, 8]]

train input:
[[1, 1, 1, 8, 0, 0, 0, 0, 0, 0], [1, 8, 1, 1, 0, 1, 8, 8, 1, 8], [8, 2, 8, 1, 0, 8, 1, 8, 2, 8], [1, 1, 1, 8, 0, 8, 8, 8, 8, 1], [8, 1, 8, 8, 0, 8, 1, 2, 8, 2], [0, 0, 0, 0, 0, 8, 8, 8, 1, 8], [0, 0, 0, 0, 0, 1, 1, 8, 1, 8], [0, 8, 2, 2, 0, 8, 1, 1, 8, 2], [0, 2, 2, 1, 0, 0, 0, 0, 0, 0], [0, 2, 1, 8, 0, 0, 0, 0, 0, 0]]
train output:
[[8, 2, 2], [2, 2, 1], [2, 1, 8]]

train input:
[[2, 8, 8, 8, 0, 0, 0, 0, 0, 0], [8, 8, 1, 8, 0, 0, 0, 0, 0, 0], [1, 8, 8, 8, 0, 0, 0, 0, 0, 0], [8, 8, 8, 2, 0, 0, 1, 8, 8, 2], [8, 2, 8, 1, 0, 0, 8, 8, 1, 8], [8, 1, 8, 8, 0, 0, 8, 2, 8, 8], [0, 0, 0, 0, 0, 0, 8, 8, 8, 1], [0, 0, 0, 0, 0, 0, 1, 8, 8, 8], [0, 0, 0, 0, 0, 0, 8, 8, 1, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
train output:
[[2, 8, 8, 8], [8, 8, 1, 8], [1, 8, 8, 8], [8, 8, 8, 2], [8, 2, 8, 1], [8, 1, 8, 8]]

test input:
[[2, 8, 8, 8, 0, 0, 0, 0, 0, 0], [8, 8, 1, 8, 0, 0, 2, 8, 1, 0], [1, 2, 8, 1, 0, 0, 8, 8, 8, 0], [8, 8, 8, 8, 0, 0, 2, 1, 8, 0], [0, 0, 0, 0, 0, 0, 8, 8, 2, 0], [0, 0, 0, 0, 0, 0, 2, 8, 1, 0], [0, 1, 2, 8, 2, 0, 1, 8, 8, 0], [0, 8, 8, 1, 8, 0, 0, 0, 0, 0], [0, 1, 2, 8, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
################################################################

LLM answer:

test output:
[[2, 8, 8, 8], [8, 8, 1, 8], [1, 2, 8, 1], [8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 2, 8], [0, 0, 0, 0, 0, 0, 2, 8], [0, 1, 2, 8, 2, 0, 1, 8], [0, 8, 8, 1, 8], [0, 1, 2, 8, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
```

Comment: I'm not sure what you mean by "the same model". You have two different models. The first one is a linear regression model and the second one is a logistic regression model. They are very different models.

## Answer (3)

You can use `predict_proba()` to get probabilities for each class. Then you can take the max of the probabilities to get the predicted class.

Here is an example using your data:

```
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Train
X = [[0, 0, 0, 0, 0, 0, 8, 8, 8, 8], [0, 8, 8, 8, 8, 0, 8, 2, 2, 8], [0, 8, 1, 8, 8, 0, 8, 8, 8, 8], [0, 8, 8, 2, 8, 0, 8, 2, 1, 8], [0, 8, 8, 8, 8, 0, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], y=[[8, 8, 8, 8], [8, 2, 2, 8], [8, 8, 8, 8], [8, 2, 1, 8], [8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]

lr = LogisticRegression(random_state=42)
lr.fit(X, y)

# Test
Xt = [[2, 8, 8, 8, 0, 0, 0, 0, 0, 0], [8, 8, 1, 8, 0, 0, 2, 8, 1, 0], [1, 2, 8, 1, 0, 0, 8, 8, 8, 0], [8, 8, 8, 8, 0, 0, 2, 1, 8, 0], [0, 0, 0, 0, 0, 0, 8, 8, 2, 0], [0
################################################################

Solution:
[[2, 8, 1], [8, 8, 8], [2, 1, 8], [8, 8, 2], [2, 8, 1], [1, 8, 8]]

