{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & GPU Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5' #'0,1,2,3,4,5,6,7'\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Llama Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ICBU-NPU/FashionGPT-70B-V1.1\" \n",
    "#MODEL_NAME = \"TheBloke/Llama-2-70b-Chat-GPTQ\"\n",
    "MODEL_NAME = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "#test: \n",
    "#MODEL_NAME = \"meta-llama/Llama-2-70b-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbriem/miniconda3/envs/langchainTest/lib/python3.11/site-packages/langchain/__init__.py:24: UserWarning: Importing HuggingFacePipeline from langchain root module is no longer supported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be85d61c86045d8923a45539294cbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbriem/miniconda3/envs/langchainTest/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/jbriem/miniconda3/envs/langchainTest/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#################################### with llama ####################################\n",
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\"\n",
    ")\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "generation_config.max_new_tokens = 1024\n",
    "generation_config.temperature = 0.0001\n",
    "generation_config.top_p = 0.9\n",
    "generation_config.do_sample = True\n",
    "generation_config.repetition_penalty = 1.15\n",
    "\n",
    "text_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 283 ms, total: 3.44 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test LLM with a simple example\n",
    "result = llm(\n",
    "    \"Explain the difference between ChatGPT and open source LLMs in a couple of lines.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ChatGPT is a proprietary language model developed by OpenAI, while open-source LLMs are models that are available for anyone to use and modify under an open-source license. This means that ChatGPT has been trained on a specific dataset and may have biases or limitations that are not present in open-source LLMs, which can be customized and improved upon by the community.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(0, 0, 0),\n",
    "          (0, 116, 217),\n",
    "          (255, 65, 54),\n",
    "          (46, 204, 6),\n",
    "          (255, 220, 0),\n",
    "          (170, 170, 170),\n",
    "          (240, 18, 190),\n",
    "          (255, 133, 27),\n",
    "          (127, 219, 255),\n",
    "          (135, 12, 37)]\n",
    "\n",
    "def grid_to_img(grid):\n",
    "  grid = np.int32(grid)\n",
    "  scale = 10\n",
    "  img = np.zeros((grid.shape[0] * scale + 1, grid.shape[1] * scale + 1, 3), dtype=np.uint8)\n",
    "  for r in range(grid.shape[0]):\n",
    "    for c in range(grid.shape[1]):\n",
    "      img[r*scale+1:(r+1)*scale, c*scale+1:(c+1)*scale, :] = colors[grid[r, c]]\n",
    "  new_img = img.copy()\n",
    "  new_img[0::10, :, :] = np.uint8(np.round((0.7 * np.float32(img[0::10, :, :]) + 0.3 * 255)))\n",
    "  new_img[:, 0::10, :] = np.uint8(np.round((0.7 * np.float32(img[:, 0::10, :]) + 0.3 * 255)))\n",
    "  return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get context and tasks out of json\n",
    "def get_context(task_json):\n",
    "    item_delim = \", \"\n",
    "    #text = \"train:\\n\"\n",
    "    text = \"\"\n",
    "    for sample in task_json[\"train\"]:\n",
    "        text += \"train input:\\n\"\n",
    "        for row in sample[\"input\"]:\n",
    "            for i, value in enumerate(row):\n",
    "                text += str(value)\n",
    "                if i < len(row) - 1:\n",
    "                    text += item_delim\n",
    "            text += \"\\n\"\n",
    "        text += \"train output:\\n\"\n",
    "        for row in sample[\"output\"]:\n",
    "            for i, value in enumerate(row):\n",
    "                text += str(value)\n",
    "                if i < len(row) - 1:\n",
    "                    text += item_delim\n",
    "            text += \"\\n\"\n",
    "        text += \"End of example.\\n\"  \n",
    "    return text\n",
    "\n",
    "\n",
    "def get_tasks(task_json):\n",
    "    tasks = []\n",
    "    solutions = []\n",
    "    item_delim = \", \"\n",
    "    \n",
    "    for sample in task_json[\"test\"]:\n",
    "        #task = \"test:\\n\"\n",
    "        task = \"test input:\\n\"\n",
    "        for row in sample[\"input\"]:\n",
    "            for i, value in enumerate(row):\n",
    "                task += str(value)\n",
    "                if i < len(row) - 1:\n",
    "                    task += item_delim\n",
    "            task += \"\\n\"\n",
    "        task += \"test output:\\n\"\n",
    "        # solution = \"output:\\n\"\n",
    "        solution = \"\"\n",
    "        for row in sample[\"output\"]:\n",
    "            for i, value in enumerate(row):\n",
    "                solution += str(value)\n",
    "                if i < len(row) - 1:\n",
    "                    solution += item_delim\n",
    "            solution += \"\\n\"\n",
    "        tasks.append(task)\n",
    "        solutions.append(solution)\n",
    "    return tasks, solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform text back to json\n",
    "def string_to_integer_array(input_string):\n",
    "    try:\n",
    "        integer_array = []\n",
    "        # split the input string by \"\\n\"\n",
    "        input_string = [row for row in input_string.split('\\n')]\n",
    "        # Split the input string by commas and convert each substring to an integer\n",
    "        for row in input_string:\n",
    "            integer_array.append([int(num) for num in row.split(',')])\n",
    "        return integer_array\n",
    "    except ValueError:\n",
    "        # Handle the case where some elements are not valid integers\n",
    "        return None\n",
    "\n",
    "def extract_lines_with_numbers(input_string, ignore_input= False):\n",
    "    output_found= False\n",
    "    \n",
    "    # Define a regular expression pattern to match lines with arbitrary numbers separated by commas\n",
    "    pattern = r'\\d+(?:,\\s*\\d+)*'  # This pattern matches one or more digits, possibly separated by commas\n",
    "\n",
    "    # Split the input_string into lines\n",
    "    lines = input_string.split('\\n')\n",
    "\n",
    "    # Initialize an empty list to store the matched lines\n",
    "    matched_lines = []\n",
    "\n",
    "    # Initialize a flag to determine whether to ignore lines\n",
    "    ignore_lines = False\n",
    "\n",
    "    # Iterate through the lines\n",
    "    for line in lines:\n",
    "        if ignore_input and ignore_lines:\n",
    "            # If we're in ignore mode, continue until a line with text occurs\n",
    "            if len(re.findall(pattern, line)) == 0: # Check if the line contains text (ignoring leading/trailing whitespace)\n",
    "                ignore_lines = False\n",
    "            continue\n",
    "\n",
    "        # Check if the line contains \"Input\" or \"input\"\n",
    "        if ignore_input and (\"Input\" in line or \"input\" in line):\n",
    "            ignore_lines = True\n",
    "            continue\n",
    "\n",
    "        # Check if \"End of example\" is encountered\n",
    "        if \"End of example\" in line:\n",
    "            break\n",
    "\n",
    "        # Find matches in the current line and add them to the list\n",
    "        matches = re.findall(pattern, line)\n",
    "        if len(matches) > 0:\n",
    "            matched_lines.extend(matches)\n",
    "            output_found = True\n",
    "        elif output_found:\n",
    "            break\n",
    "\n",
    "    # Join the matched lines into a single string with line breaks\n",
    "    result_string = '\\n'.join(matched_lines)\n",
    "\n",
    "    return result_string\n",
    "\n",
    "def get_LLM_result_as_json(tasks, results):\n",
    "    llm_task_results = []\n",
    "    for task, result in zip(tasks, results):\n",
    "        clean_task = extract_lines_with_numbers(task)\n",
    "        input = string_to_integer_array(clean_task)\n",
    "        clean_result = extract_lines_with_numbers(result, True)\n",
    "        output = string_to_integer_array(clean_result) \n",
    "        d = {\"input\": input, \"output\": output}\n",
    "        llm_task_results.append(d)\n",
    "    llm_task_results = dict({\n",
    "        \"test\": llm_task_results,\n",
    "    })\n",
    "    return llm_task_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tasks: 800\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "tasks_jsons = []\n",
    "tasks_names = []\n",
    "tasks_len = []\n",
    "task_dir = \"../ARC/ARC/data/training\"\n",
    "for task_file in sorted(os.listdir(task_dir)):\n",
    "  with open(os.path.join(task_dir, task_file)) as fid:\n",
    "    task_json = json.load(fid)\n",
    "  tasks_jsons.append(task_json)\n",
    "  tasks_names.append(task_file)\n",
    "\n",
    "\n",
    "task_dir = \"../ARC/ARC/data/evaluation\"\n",
    "for task_file in sorted(os.listdir(task_dir)):\n",
    "  with open(os.path.join(task_dir, task_file)) as fid:\n",
    "    task_json = json.load(fid)\n",
    "  tasks_jsons.append(task_json)\n",
    "  tasks_names.append(task_file)\n",
    "\n",
    "\n",
    "print(\"Total number of tasks:\", len(tasks_jsons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 800\n",
      "007bbfb7.json Success: 0 Total: 0 / 1\n",
      "2 / 800\n",
      "00d62c1b.json Prompt too long.\n",
      "2 / 800\n",
      "017c7c7b.json Success: 0 Total: 0 / 2\n",
      "Done. Success log:\n",
      "Too long prompts: 1\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "# Format the date and time as a string \n",
    "directory = \"results/\"+current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# My Approach: \n",
    "token_limit = 4096\n",
    "success = {}\n",
    "success_log = []\n",
    "task_counter = 1\n",
    "promp_oversize_counter = 0\n",
    "for task_json, task_name in zip(tasks_jsons, tasks_names):\n",
    "  print(task_counter, \"/\", len(tasks_jsons))\n",
    "  # Lazy load: skip evals where we already have results.\n",
    "  # if task_name in success:\n",
    "  #   continue\n",
    "\n",
    "  context = \"Do not give explanation.\\n\"\n",
    "  context = \"I present train examples of input and output pairs. Please return the missing test output.\\n\"\n",
    "  context = \"\"\n",
    "  # Build context and expected output labels.\n",
    "  context += get_context(task_json)\n",
    "  tasks, solutions = get_tasks(task_json)\n",
    "\n",
    "  if len(tokenizer.encode(context+tasks[0])) > token_limit:\n",
    "    print(task_name, \"Prompt too long.\")\n",
    "    promp_oversize_counter += 1\n",
    "    continue\n",
    "\n",
    "  # Run LLM.\n",
    "  for task in tasks:\n",
    "    results = []\n",
    "    try:\n",
    "      results.append(llm(context+task))\n",
    "    except Exception as e:\n",
    "      print(task_name, f\"LLM failed. {e}\")\n",
    "      continue\n",
    "\n",
    "  # Check answers and save success rates.\n",
    "  success[task_name] = 0\n",
    "  for result, solution in zip(results, solutions):\n",
    "    # label_str = tokenizer.decode(label, skip_special_tokens=True)\n",
    "    is_success = solution.strip() in result\n",
    "    success[task_name] += is_success / len(solutions)\n",
    "  success[task_name] = int(success[task_name] > 0.99)  # All test cases need to correct.\n",
    "\n",
    "  # Debug prints.\n",
    "  total_success = np.sum(list(success.values()))\n",
    "  print(task_name, \"Success:\", success[task_name], \"Total:\", f\"{total_success} / {len(success)}\")\n",
    "\n",
    "  # Save task result in log file, if solved at least one.\n",
    "  if success[task_name] > 0:\n",
    "    success_log.append((task_name,total_success/len(success)))\n",
    "  # save LLM task output as json file\n",
    "  try:\n",
    "    LLM_result_json = get_LLM_result_as_json(tasks, results) \n",
    "    with open(directory+\"/\"+task_name+\"_LLM_result.json\", \"w\") as json_file:\n",
    "      json.dump(LLM_result_json, json_file)\n",
    "  except Exception as e:\n",
    "    print(\"Failed to write LLM result as .json file for task \"+task_name, f\"Error: {e}\")\n",
    "    continue\n",
    "  # save LLM result as txt file\n",
    "  try:\n",
    "    LLM_answer = \"\"\n",
    "    for i, result in enumerate(results):\n",
    "      LLM_answer += f\"LLM answer for tasks {i+1}:\\n{result}\\n\"\n",
    "    with open(directory+\"/\"+task_name+\"_LLM_answer.txt\", \"w\") as text_file:\n",
    "      text_file.write(LLM_answer)\n",
    "  except Exception as e:\n",
    "    print(\"Failed to write LLM answer as .txt file for task \"+task_name, f\"Error: {e}\")\n",
    "    continue\n",
    "  task_counter += 1\n",
    "print(\"Done. Success log:\")\n",
    "print(\"Too long prompts:\", promp_oversize_counter)\n",
    "print(success_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context+tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?,?,?\\n?,?,?\\n?,?,?\\n?,?,?\\n?,?,?\\n?,?,?\\nPlease provide the missing test output.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(context+tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5, 3, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 3, 0, 0, 3, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 3, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 3, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 3, 0, 0, 4\\n5, 0, 3, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 3, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 3, 0, 0, 0, 0, 4\\nEnd of example.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test:\\ninput:\\n7, 0, 7\\n7, 0, 7\\n7, 7, 0\\noutput:\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks, solutions = get_tasks(tasks_jsons[0])\n",
    "#new = delete_substring(tasks[0], \"test:\\ninput:\")\n",
    "#new\n",
    "tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test input:\\n5, 3, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 3, 0, 0, 3, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 3, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 3, 0, 0, 4\\n5, 0, 0, 3, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 3, 0, 0, 0, 0, 4\\n5, 0, 3, 0, 0, 0, 3, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\ntest output:\\n']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': [[5, 3, 0, 0, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 3, 0, 0, 3, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 3, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 3, 0, 0, 4],\n",
       "   [5, 0, 0, 3, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 3, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 3, 0, 0, 0, 3, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 0, 0, 0, 4]],\n",
       "  'output': [[5, 5, 0, 0, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 4, 0, 0, 4, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 5, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 4, 0, 0, 4],\n",
       "   [5, 0, 0, 5, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 5, 0, 0, 0, 0, 4],\n",
       "   [5, 0, 5, 0, 0, 0, 4, 0, 0, 4],\n",
       "   [5, 0, 0, 0, 0, 0, 0, 0, 0, 4]]}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_json[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test input:\\n5, 3, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 3, 0, 0, 3, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 3, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 3, 0, 0, 4\\n5, 0, 0, 3, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\n5, 0, 0, 0, 3, 0, 0, 0, 0, 4\\n5, 0, 3, 0, 0, 0, 3, 0, 0, 4\\n5, 0, 0, 0, 0, 0, 0, 0, 0, 4\\ntest output:\\n']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': [{'input': [[5, 3, 0, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 0, 3, 0, 0, 3, 4], [5, 0, 0, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 3, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 0, 0, 3, 0, 0, 4], [5, 0, 0, 3, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 3, 0, 0, 0, 0, 4], [5, 0, 3, 0, 0, 0, 3, 0, 0, 4], [5, 0, 0, 0, 0, 0, 0, 0, 0, 4]], 'output': [[5, 3, 0, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 0, 3, 0, 0, 3, 4], [5, 0, 0, 0, 0, 0, 0, 0, 0, 4], [5, 0, 3, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 3, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 0, 0, 3, 0, 0, 4], [5, 0, 3, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 3, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 0, 0, 0, 0, 0, 4], [5, 0, 0, 0, 3, 0, 0, 0, 0, 4]]}]}\n"
     ]
    }
   ],
   "source": [
    "llm_task_results = []\n",
    "for task, result in zip(tasks, results):\n",
    "    # ist quatsch für task und solution, da die ja schon als json vorliegen\n",
    "    # clean_task = delete_substring(task, \"test:\\ninput:\\n\")\n",
    "    # clean_task = delete_substring(clean_task, \"\\noutput:\\n\")\n",
    "    clean_task = extract_lines_with_numbers(task)\n",
    "    input = string_to_integer_array(clean_task)\n",
    "    clean_result = extract_lines_with_numbers(result, True)\n",
    "    output = string_to_integer_array(clean_result) \n",
    "    d = {\"input\": input, \"output\": output}\n",
    "    llm_task_results.append(d)\n",
    "llm_task_results = dict({\n",
    "    \"test\": llm_task_results,\n",
    "})\n",
    "print(llm_task_results)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"input:\\n7, 0, 7\\n7, 0, 7\\n7, 7, 0\\noutput:\\n7, 0, 7, 0, 0, 0, 7, 0, 7\\n7, 0, 7, 0, 0, 0, 7, 0, 7\\n7, 7, 0, 0, 0, 0, 7, 7, 0\\n7, 0, 7, 0, 0, 0, 7, 0, 7\\n7, 0, 7, 0, 0, 0, 7, 0, 7\\n7, 7, 0, 0, 0, 0, 7, 7, 0\\n7, 0, 7, 7, 0, 7, 0, 0, 0\\n7, 0, 7, 7, 0, 7, 0, 0, 0\\n7, 7, 0, 7, 7, 0, 0, 0, 0\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helle\n",
      "5, 3, 0, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 0, 3, 0, 0, 3, 4\n",
      "5, 0, 0, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 3, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 3, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 0, 0, 3, 0, 0, 4\n",
      "5, 0, 3, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 3, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 3, 0, 0, 0, 0, 4\n",
      "End of example.\n"
     ]
    }
   ],
   "source": [
    "print(\"helle\\n\"+results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5, 3, 0, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 0, 3, 0, 0, 3, 4\n",
      "5, 0, 0, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 3, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 3, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 0, 0, 3, 0, 0, 4\n",
      "5, 0, 3, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 3, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 0, 0, 0, 0, 0, 4\n",
      "5, 0, 0, 0, 3, 0, 0, 0, 0, 4\n"
     ]
    }
   ],
   "source": [
    "print(extract_lines_with_numbers(task+results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3\n",
      "4, 5, 6\n",
      "7, 8, 9\n",
      "10, 11, 12, 13\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = \"0,0,1,0,0\\n\"\n",
    "string_to_integer_list(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict({\n",
    "    \"input\": \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [{'input': [[0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "    [0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 4, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 5]],\n",
       "   'output': [[0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 4, 2, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 0, 0, 0, 5, 0],\n",
       "    [0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 2, 2, 2, 2, 2, 0],\n",
       "    [5, 0, 0, 0, 2, 2, 2, 2, 2, 0],\n",
       "    [0, 0, 0, 0, 2, 2, 4, 2, 2, 0],\n",
       "    [0, 0, 0, 0, 2, 2, 2, 2, 2, 0],\n",
       "    [0, 5, 0, 0, 2, 2, 2, 2, 2, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 5]]},\n",
       "  {'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 5, 0, 0, 4, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 5, 2, 2, 4, 2, 2, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]},\n",
       "  {'input': [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 4, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   'output': [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 0, 2, 4, 2, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0]]},\n",
       "  {'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 4, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0]]}],\n",
       " 'test': [{'input': [[0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "   'output': [[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 2, 4, 2, 2, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 5, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 4, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 5, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0],\n",
       "    [0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show problem.\n",
    "print(\"TRAIN:\")\n",
    "for i, ex in enumerate(example_json[\"train\"]):\n",
    "  in_img = grid_to_img(ex[\"input\"])\n",
    "  out_img = grid_to_img(ex[\"output\"])\n",
    "  plt.subplot(1, 2, 1); plt.imshow(grid_to_img(ex[\"input\"]))\n",
    "  plt.subplot(1, 2, 2); plt.imshow(grid_to_img(ex[\"output\"]))\n",
    "  plt.show()\n",
    "print(\"TEST:\")\n",
    "for i, ex in enumerate(example_json[\"test\"]):\n",
    "  in_img = grid_to_img(ex[\"input\"])\n",
    "  out_img = grid_to_img(ex[\"output\"])\n",
    "  plt.subplot(1, 2, 1); plt.imshow(grid_to_img(ex[\"input\"]))\n",
    "  plt.subplot(1, 2, 2); plt.imshow(grid_to_img(ex[\"output\"]))\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainTest",
   "language": "python",
   "name": "langchaintest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
